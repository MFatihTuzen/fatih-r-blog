{
  "hash": "9f1a80d8ab8a3ff5b2e261468cc183cd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Underrated Gems in R: Must-Know Functions You’re Probably Missing Out On\"\nauthor: \"M. Fatih Tüzen\"\ndate: \"2025-03-11\"\ncategories: [reduce, vapply, do.call, clean_names]\nimage: gems.jpg\n---\n\n\n\nR is packed with powerhouse tools—think dplyr for data wrangling, ggplot2 for stunning visuals, or tidyr for tidying up messes. But beyond the headliners, there’s a lineup of lesser-known functions that deserve a spot in your toolkit. These hidden gems can streamline your code, solve tricky problems, and even make you wonder how you managed without them. In this post, we’ll uncover four underrated R functions: **`Reduce, vapply, do.call`** and **`janitor::clean_names`**. With practical examples ranging from beginner-friendly to advanced, plus outputs to show you what’s possible, this guide will have you itching to try them out in your next project. Let’s dive in and see what these under-the-radar stars can do!\n\n## 1. Reduce: Collapse with Control\n\n### What It Does and Its Arguments\n\nReduce is a base R function that iteratively applies a two-argument function to a list or vector, shrinking it down to a single result. It’s like a secret weapon for avoiding loops while keeping things elegant.\n\n**Key Arguments:**\n\n-   `f:` The function to apply (e.g., +, \\*, or a custom one).\n\n-   `x:` The list or vector to reduce.\n\n-   `init` (optional): A starting value (defaults to the first element of x if omitted).\n\n-   `accumulate` (optional): If TRUE, returns all intermediate results (defaults to FALSE).\n\n### Use Cases\n\n-   Summing or multiplying without explicit iteration.\n\n-   Combining data structures step-by-step.\n\n-   Simplifying recursive tasks.\n\n### Examples\n\n#### Simple: Quick Sum\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumbers <- 1:5\ntotal <- Reduce(`+`, numbers)\nprint(total)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* Reduce adds 1 + 2 = 3, then 3 + 3 = 6, 6 + 4 = 10, and 10 + 5 = 15. It’s a sleek alternative to sum().\n\n#### Intermediate: String Building\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwords <- c(\"R\", \"is\", \"awesome\")\nsentence <- Reduce(paste, words, init = \"\")\nprint(sentence)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \" R is awesome\"\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* Starting with an empty string (init = \"\"), Reduce glues the words together with spaces. Skip init, and it starts with \"R\", which might not be what you want.\n\n#### Advanced: Merging Data Frames\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1 <- data.frame(a = 1:2, b = c(\"x\", \"y\"))\ndf2 <- data.frame(a = 3:4, b = c(\"z\", \"w\"))\ndf3 <- data.frame(a = 5:6, b = c(\"p\", \"q\"))\ncombined <- Reduce(rbind, list(df1, df2, df3))\nprint(combined)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a b\n1 1 x\n2 2 y\n3 3 z\n4 4 w\n5 5 p\n6 6 q\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* Reduce stacks three data frames row-wise, pairing them up one by one. It’s a loop-free way to handle multiple merges.\n\n::: callout-note\n## A Quick Note on purrr::reduce()\n\nIf you’re a fan of the tidyverse, check out purrr::reduce(). It’s a modern take on base R’s Reduce, offering a consistent syntax with other purrr functions (like .x and .y for arguments) and handy shortcuts like \\~ .x + .y for inline functions. It also defaults to left-to-right reduction but can go right-to-left with reduce_right(). Worth a look if you want a more polished, tidyverse-friendly alternative!\n\nHere's an intermediate-level example of using the `reduce()` function from the `purrr` package for joining multiple dataframes:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(dplyr)\n\n# Create three sample dataframes representing different aspects of customer data\ncustomers <- data.frame(\n  customer_id = 1:5,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Edward\"),\n  age = c(32, 45, 28, 36, 52)\n)\n\norders <- data.frame(\n  order_id = 101:108,\n  customer_id = c(1, 2, 2, 3, 3, 3, 4, 5),\n  order_date = as.Date(c(\"2023-01-15\", \"2023-01-20\", \"2023-02-10\", \n                        \"2023-01-05\", \"2023-02-15\", \"2023-03-20\",\n                        \"2023-02-25\", \"2023-03-10\")),\n  amount = c(120.50, 85.75, 200.00, 45.99, 75.25, 150.00, 95.50, 210.25)\n)\n\nfeedback <- data.frame(\n  feedback_id = 201:206,\n  customer_id = c(1, 2, 3, 3, 4, 5),\n  rating = c(4, 5, 3, 4, 5, 4),\n  feedback_date = as.Date(c(\"2023-01-20\", \"2023-01-25\", \"2023-01-10\",\n                          \"2023-02-20\", \"2023-03-01\", \"2023-03-15\"))\n)\n\n# List of dataframes to join with the joining column\ndataframes_to_join <- list(\n  list(df = customers, by = \"customer_id\"),\n  list(df = orders, by = \"customer_id\"),\n  list(df = feedback, by = \"customer_id\")\n)\n\n# Using reduce to join all dataframes\n# Start with customers dataframe and progressively join the others\njoined_data <- reduce(\n  dataframes_to_join[-1],  # Exclude first dataframe as it's our starting point\n  function(acc, x) {\n    left_join(acc, x$df, by = x$by)\n  },\n  .init = dataframes_to_join[[1]]$df  # Start with customers dataframe\n)\n\n# View the result\nprint(joined_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   customer_id    name age order_id order_date amount feedback_id rating\n1            1   Alice  32      101 2023-01-15 120.50         201      4\n2            2     Bob  45      102 2023-01-20  85.75         202      5\n3            2     Bob  45      103 2023-02-10 200.00         202      5\n4            3 Charlie  28      104 2023-01-05  45.99         203      3\n5            3 Charlie  28      104 2023-01-05  45.99         204      4\n6            3 Charlie  28      105 2023-02-15  75.25         203      3\n7            3 Charlie  28      105 2023-02-15  75.25         204      4\n8            3 Charlie  28      106 2023-03-20 150.00         203      3\n9            3 Charlie  28      106 2023-03-20 150.00         204      4\n10           4   Diana  36      107 2023-02-25  95.50         205      5\n11           5  Edward  52      108 2023-03-10 210.25         206      4\n   feedback_date\n1     2023-01-20\n2     2023-01-25\n3     2023-01-25\n4     2023-01-10\n5     2023-02-20\n6     2023-01-10\n7     2023-02-20\n8     2023-01-10\n9     2023-02-20\n10    2023-03-01\n11    2023-03-15\n```\n\n\n:::\n:::\n\n\n\nThis example demonstrates how to use `reduce()` to join multiple dataframes in a sequential, elegant way. This pattern is particularly useful when dealing with complex data integration tasks where you need to combine multiple data sources with a common identifier.\n:::\n\n## 2. vapply: Iteration with Assurance\n\n### What It Does and Its Arguments\n\nvapply is another base R gem, similar to lapply but with a twist: it forces you to specify the output type and length upfront. This makes it safer and more predictable, especially for critical tasks.\n\n**Key Arguments:**\n\n-   `X`: The list or vector to process.\n\n-   `FUN`: The function to apply to each element.\n\n-   `FUN.VALUE`: A template for the output (e.g., numeric(1) for a single number).\n\n### Use Cases\n\n-   Guaranteeing consistent output types.\n\n-   Extracting specific stats from lists.\n\n-   Writing reliable code for packages or production.\n\n### Examples\n\n#### Simple: Doubling Up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalues <- 1:3\ndoubled <- vapply(values, function(x) x * 2, numeric(1))\nprint(doubled)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2 4 6\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* Each value doubles, and numeric(1) ensures a numeric vector—simple and rock-solid.\n\n#### Intermediate: Word Lengths\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterms <- c(\"data\", \"science\", \"R\")\nlengths <- vapply(terms, nchar, numeric(1))\nprint(lengths)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   data science       R \n      4       7       1 \n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* vapply counts characters per word, delivering a numeric vector every time—no surprises like sapply might throw.\n\n#### Advanced: Stats Snapshot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples <- list(c(1, 2, 3), c(4, 5), c(6, 7, 8))\nstats <- vapply(samples, function(x) c(mean = mean(x), sd = sd(x)), numeric(2))\nprint(stats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]      [,2] [,3]\nmean    2 4.5000000    7\nsd      1 0.7071068    1\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* For each sample, vapply computes mean and standard deviation, returning a matrix (2 rows, 3 columns). It’s a tidy, type-safe summary.\n\n## 3. do.call: Dynamic Function Magic\n\n### What It Does and Its Arguments\n\ndo.call in base R lets you call a function with a list of arguments, making it a go-to for flexible, on-the-fly operations. It’s like having a universal remote for your functions.\n\n**Key Arguments:**\n\n-   `what`: The function to call (e.g., rbind, paste).\n\n-   `args`: A list of arguments to pass.\n\n-   `quote` (optional): Rarely used, defaults to FALSE.\n\n### Use Cases\n\n-   Combining variable inputs.\n\n-   Running functions dynamically.\n\n-   Simplifying calls with list-based data.\n\n### Examples\n\n#### Simple: Vector Mashup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchunks <- list(1:3, 4:6)\nall <- do.call(c, chunks)\nprint(all)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4 5 6\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* do.call feeds the list to c(), stitching the vectors together effortlessly.\n\n#### Intermediate: Custom Join\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbits <- list(\"Code\", \"Runs\", \"Fast\")\njoined <- do.call(paste, c(bits, list(sep = \"|\")))\nprint(joined)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Code|Runs|Fast\"\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* do.call combines the list with a sep argument, creating a piped string in one smooth move.\n\n#### Advanced: Flexible Binding\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_list <- list(data.frame(x = 1:2), data.frame(x = 3:4))\ndirection <- \"vertical\"\nbound <- do.call(if (direction == \"vertical\") rbind else cbind, df_list)\nprint(bound)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  x\n1 1\n2 2\n3 3\n4 4\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* With direction = \"vertical\", do.call uses rbind to stack rows. Change it to \"horizontal\", and cbind takes over—dynamic and smart.\n\n## 4. janitor::clean_names: Tame Your Column Chaos\n\n### What It Does and Its Arguments\n\nFrom the janitor package, clean_names() transforms messy column names into consistent, code-friendly formats (e.g., lowercase with underscores). It’s a time-saver you’ll wish you’d known sooner.\n\n**Key Arguments:**\n\n-   `dat`: The data frame to clean.\n\n-   `case`: The style for names (e.g., \"snake\", \"small_camel\", defaults to \"snake\").\n\n-   `replace`: A named vector for custom replacements (optional).\n\n### Use Cases\n\n-   Standardizing imported data with ugly headers.\n\n-   Prepping data frames for analysis or plotting.\n\n-   Avoiding frustration with inconsistent naming.\n\n### Examples\n\n#### Simple: Basic Cleanup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\n\n# Create a dataframe with messy column names\ndf <- data.frame(\n  `First Name` = c(\"John\", \"Mary\", \"David\"),\n  `Last.Name` = c(\"Smith\", \"Johnson\", \"Williams\"),\n  `Email-Address` = c(\"john@example.com\", \"mary@example.com\", \"david@example.com\"),\n  `Annual Income ($)` = c(65000, 78000, 52000),\n  check.names = FALSE\n)\n\n# View original column names\nnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"First Name\"        \"Last.Name\"         \"Email-Address\"    \n[4] \"Annual Income ($)\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Clean the names\nclean_df <- clean_names(df)\n\n# View cleaned column names\nnames(clean_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"first_name\"    \"last_name\"     \"email_address\" \"annual_income\"\n```\n\n\n:::\n:::\n\n\n\nWhat `clean_names()` specifically does:\n\n-   Converts all names to lowercase\n\n-   Replaces spaces with underscores\n\n-   Removes special characters like periods and hyphens\n\n-   Creates names that are valid R variable names and follow standard naming conventions\n\nThis standardization makes your data more consistent, easier to work with, and helps prevent errors when manipulating or joining datasets.\n\n#### Intermediate: Custom Style\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(purrr)\n\n# Create multiple dataframes with inconsistent naming\ndf1 <- data.frame(\n  `Customer ID` = 1:3,\n  `First Name` = c(\"John\", \"Mary\", \"David\"),\n  `LAST NAME` = c(\"Smith\", \"Johnson\", \"Williams\"),\n  check.names = FALSE\n)\n\ndf2 <- data.frame(\n  `customer.id` = 4:6,\n  `firstName` = c(\"Michael\", \"Linda\", \"James\"),\n  `lastName` = c(\"Brown\", \"Davis\", \"Miller\"),\n  check.names = FALSE\n)\n\ndf3 <- data.frame(\n  `cust_id` = 7:9,\n  `first-name` = c(\"Robert\", \"Jennifer\", \"Thomas\"),\n  `last-name` = c(\"Wilson\", \"Martinez\", \"Anderson\"),\n  check.names = FALSE\n)\n\n# List of dataframes\ndfs <- list(df1, df2, df3)\n\n# Clean names of all dataframes\nclean_dfs <- map(dfs, clean_names)\n\n# Print column names for each cleaned dataframe\nmap(clean_dfs, names)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"customer_id\" \"first_name\"  \"last_name\"  \n\n[[2]]\n[1] \"customer_id\" \"first_name\"  \"last_name\"  \n\n[[3]]\n[1] \"cust_id\"    \"first_name\" \"last_name\" \n```\n\n\n:::\n\n```{.r .cell-code}\n# Bind the dataframes (now possible because of standardized column names)\ncombined_df <- bind_rows(clean_dfs)\nprint(combined_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  customer_id first_name last_name cust_id\n1           1       John     Smith      NA\n2           2       Mary   Johnson      NA\n3           3      David  Williams      NA\n4           4    Michael     Brown      NA\n5           5      Linda     Davis      NA\n6           6      James    Miller      NA\n7          NA     Robert    Wilson       7\n8          NA   Jennifer  Martinez       8\n9          NA     Thomas  Anderson       9\n```\n\n\n:::\n:::\n\n\n\nThis code demonstrates a more advanced use case of the `clean_names()` function when working with multiple data frames that have inconsistent naming conventions. Note that because of the different column names for customer ID, we have missing values in the combined dataframe. This example demonstrates why standardized naming is important.\n\n#### Advanced: Targeted Fixes\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(\"ID#\" = 1:2, \"Sales_%\" = c(10, 20), \"Q1 Revenue\" = c(100, 200))\ncleaned <- clean_names(df, replace = c(\"#\" = \"_num\", \"%\" = \"_pct\"))\nprint(names(cleaned))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"id\"         \"sales\"      \"q1_revenue\"\n```\n\n\n:::\n:::\n\n\n\n***Explanation**:* Custom replace swaps \\# for \\_num and % for \\_pct, while clean_names handles the rest—precision meets polish.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\n\n\n# Create a temporary Excel file with problematic column names\ntemp_file <- tempfile(fileext = \".xlsx\")\ndf <- data.frame(\n  `ID#` = 1:5,\n  `%_Completed` = c(85, 92, 78, 100, 65),\n  `Result (Pass/Fail)` = c(\"Pass\", \"Pass\", \"Fail\", \"Pass\", \"Fail\"),\n  `μg/mL` = c(0.5, 0.8, 0.3, 1.2, 0.4),\n  `p-value` = c(0.03, 0.01, 0.08, 0.002, 0.06),\n  check.names = FALSE\n)\n\n# Save as Excel (simulating real-world data source)\nif (require(writexl)) {\n  write_xlsx(df, temp_file)\n} else {\n  # Fall back to CSV if writexl not available\n  write.csv(df, sub(\"\\\\.xlsx$\", \".csv\", temp_file), row.names = FALSE)\n  temp_file <- sub(\"\\\\.xlsx$\", \".csv\", temp_file)\n}\n\n# Read the file back\nif (temp_file == sub(\"\\\\.xlsx$\", \".csv\", temp_file)) {\n  imported_df <- read.csv(temp_file, check.names = FALSE)\n} else {\n  imported_df <- read_excel(temp_file)\n}\n\n# View original column names\nprint(names(imported_df))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ID#\"                \"%_Completed\"        \"Result (Pass/Fail)\"\n[4] \"μg/mL\"              \"p-value\"           \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create custom replacements\ncustom_replacements <- c(\n  \"μg\" = \"ug\",  # Replace Greek letter\n  \"%\" = \"percent\",  # Replace percent symbol\n  \"#\" = \"num\"   # Replace hash\n)\n\n# Clean with custom replacements\nclean_df <- imported_df %>%\n  clean_names() %>%\n  rename_with(~ stringr::str_replace_all(., \"p_value\", \"probability\"))\n\n# View cleaned column names\nprint(names(clean_df))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"id_number\"         \"percent_completed\" \"result_pass_fail\" \n[4] \"mg_m_l\"            \"probability\"      \n```\n\n\n:::\n\n```{.r .cell-code}\n# Print the cleaned dataframe\nprint(clean_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n  id_number percent_completed result_pass_fail mg_m_l probability\n      <dbl>             <dbl> <chr>             <dbl>       <dbl>\n1         1                85 Pass                0.5       0.03 \n2         2                92 Pass                0.8       0.01 \n3         3                78 Fail                0.3       0.08 \n4         4               100 Pass                1.2       0.002\n5         5                65 Fail                0.4       0.06 \n```\n\n\n:::\n:::\n\n\n\nThe final output shows the transformation from problematic column names to standardized ones:\n\nFrom:\n\n-   `ID#`\n\n-   `%_Completed`\n\n-   `Result (Pass/Fail)`\n\n-   `μg/mL`\n\n-   `p-value`\n\nTo:\n\n-   `id_num`\n\n-   `percent_completed`\n\n-   `result_pass_fail`\n\n-   `ug_m_l`\n\n-   `probability`\n\nThis example demonstrates how `clean_names()` can be part of a more sophisticated data preparation workflow, especially when working with real-world data sources that contain problematic characters and naming conventions.\n\n## Conclusion: Why These Functions Deserve Your Attention\n\nR’s ecosystem is vast, but it’s easy to stick to the familiar and miss out on tools like Reduce, vapply, do.call and clean_names. These functions might not top the popularity charts, yet they pack a punch—whether it’s collapsing data without loops, ensuring type safety, adapting on the fly, fixing messy names, or mining text for gold. The examples here show just a taste of what they can do, from quick fixes to complex tasks. Curious to see how they fit into your workflow? Fire up R, play with them, and discover how these underdogs can become your new go-tos. What other hidden R treasures have you found? Drop them in the comments—I’d love to hear!\n\n## References\n\n-   R Core Team (2025). *R: A Language and Environment for Statistical Computing*. R Foundation for Statistical Computing, Vienna, Austria. Available at: <https://www.R-project.org/>\n\n-   Firke, Sam (2023). *janitor: Simple Tools for Examining and Cleaning Dirty Data*. CRAN. Available at: <https://CRAN.R-project.org/package=janitor>\n\n-   R Documentation for Reduce, vapply, do.call, clean_names.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}