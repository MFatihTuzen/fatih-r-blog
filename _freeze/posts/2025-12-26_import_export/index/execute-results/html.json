{
  "hash": "551b48bf924f08c1486324a758fee15c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding Data Import and Export in R: Working with CSV and Excel Files\"\nauthor: \"M. Fatih Tüzen\"\ndate: \"2025-12-26\"\ncategories: [R Programming, Data Analysis, Data Science, CSV, Excel,Data Import, Data Export]\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    number-sections: true\n    code-tools: true\n    code-overflow: scroll\n    code-block-background: true\n  pdf:\n    toc: true\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n![](import_export.png){fig-align=\"center\" width=\"477\"}\n\n## Introduction\n\nWhen learning R, most people focus on functions, models, and visualizations. However, many real-world problems start much earlier — at the **data import stage** — and end much later — with **exporting results**.\n\nIf data is read incorrectly, no statistical method can save the analysis.\n\nIn this post, we focus on the **logic of data import and export in R**, using **CSV and Excel files**. Rather than memorizing functions, we build a mental model for how R interacts with files.\n\n## Why Data Import and Export Matters\n\nData analysis is a workflow:\n\n``` mathematica\nData source → Import → Analysis → Results → Export → Sharing\n```\n\nErrors often occur at the *import* stage:\n\n-   wrong delimiters,\n\n-   incorrect decimal separators,\n\n-   incorrect file paths,\n\n-   silently converted data types.\n\nThe result?\\\nA model that runs perfectly — on the **wrong data**.\n\n## CSV vs Excel: Not a Competition\n\nBefore touching R, we should clarify the difference between file formats.\n\n### CSV Files\n\n-   Plain text files\n\n-   Lightweight and fast\n\n-   Universally supported\n\n-   One table per file\n\n-   No formatting, only data\n\nExample:\n\n```         \ntotal_bill,tip,sex\n16.99,1.01,Female\n```\n\n### Excel Files\n\n-   Binary format (`.xlsx`)\n\n-   Can contain multiple sheets\n\n-   Store structure and presentation together\n\n-   Widely used for reporting and sharing\n\n**Key idea:**\\\nCSV is a *data transport format*.\\\nExcel is a *communication format*.\n\n## Working Directory: Where R Actually Looks\n\nOne of the most common beginner mistakes has nothing to do with R syntax.\n\nR does **not** search your entire computer for files. It only looks inside its **working directory**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n:::\n\n\nThis command shows where R is currently looking.\n\nIf a file exists on your computer but not in this directory, R behaves as if the file does not exist.\n\nThis is why errors like:\n\n``` pssql\ncannot open the connection\n```\n\nusually indicate a **path problem**, not a coding problem.\n\n## The Example Dataset: `tips`\n\nThroughout this post, we use a single dataset: **tips**.\n\n-   Restaurant tipping data\n\n-   Small and easy to understand\n\n-   Contains numeric and categorical variables\n\n-   Ideal for demonstrating import/export logic\n\nData source:\\\n<https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv>\n\n## Reading CSV Files: The Core Logic\n\nWhen R reads a CSV file, it needs answers to four questions:\n\n1.  How are columns separated?\n\n2.  Is the first row a header?\n\n3.  What is the decimal separator?\n\n4.  How should text be interpreted?\n\nThese answers are provided via **function arguments**.\n\n## `read.table()`: The Foundation\n\nAll CSV-reading functions in base R are built on `read.table()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips <- read.table(\n  file = \"tips.csv\",\n  header = TRUE,\n  sep = \",\",\n  dec = \".\",\n  stringsAsFactors = FALSE\n)\n```\n:::\n\n\nUnderstanding this function means understanding CSV import in R.\n\n## `read.csv()` and Its Assumptions\n\n`read.csv()` is simply a shortcut for a common case:\n\n-   Columns separated by commas\n\n-   Decimal separator is a dot\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips <- read.csv(\"tips.csv\")\n```\n:::\n\n\nThis works perfectly — **if the assumptions match the file**.\n\nThe dangerous part? R may not throw an error even if the assumptions are wrong.\n\n> The most dangerous errors are silent ones.\n\n## `read.csv2()` and Regional Differences\n\nIn many European datasets:\n\n-   Columns are separated by semicolons\n\n-   Decimals use commas\n\n```         \ntotal_bill;tip;sex\n16,99;1,01;Female\n```\n\nFor this structure, `read.csv2()` is designed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips2 <- read.csv2(\"tips_semicolon.csv\")\n```\n:::\n\n\nImportant nuance:\\\nEven if decimals use dots, `read.csv2()` may still work in some cases — but **this is not guaranteed**.\n\nCorrect approach:\n\n> Always inspect the file structure before choosing the function.\n\n## Writing CSV Files from R\n\nData analysis rarely ends in R. Results are shared as files.\n\n### Writing comma-separated CSV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(tips, \"tips_comma.csv\", row.names = FALSE)\n```\n:::\n\n\n### Writing semicolon-separated CSV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv2(tips, \"tips_semicolon.csv\", row.names = FALSE)\n```\n:::\n\n\nChoosing the correct format depends on **who will read the file next**.\n\n## Why We Still Need Excel\n\nCSV is technically superior in many ways. Yet Excel remains dominant in practice.\n\nWhy?\n\n-   Multiple tables in one file\n\n-   Familiar interface for non-technical users\n\n-   Common reporting format\n\nExcel is not an analysis tool — but it *is* a powerful delivery tool.\n\n## Working with Excel in R: `openxlsx`\n\nThe `openxlsx` package allows Excel operations **without requiring Excel itself**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openxlsx)\n```\n:::\n\n\n### Writing a simple Excel file\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.xlsx(tips, \"tips.xlsx\", sheetName = \"tips\")\n```\n:::\n\n\n### Reading from Excel\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips_excel <- read.xlsx(\"tips.xlsx\", sheet = 1)\n```\n:::\n\n\n## Multiple Sheets: A Mini Report\n\nExcel shines when organizing related tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_tips <- aggregate(tip ~ day, data = tips, mean)\n\nwb <- createWorkbook()\n\naddWorksheet(wb, \"Raw Data\")\nwriteData(wb, \"Raw Data\", tips)\n\naddWorksheet(wb, \"Summary\")\nwriteData(wb, \"Summary\", summary_tips)\n\nsaveWorkbook(wb, \"tips_report.xlsx\", overwrite = TRUE)\n```\n:::\n\n\nOne file.\\\n\nMultiple views.\\\n\nClean structure.\n\n## Common Mistakes to Watch For\n\nMost errors are not caused by R, but by assumptions:\n\n-   Incorrect working directory\n\n-   Wrong delimiter (`sep`)\n\n-   Wrong decimal separator (`dec`)\n\n-   Reading the wrong Excel sheet\n\n-   Overwriting files unintentionally\n\nA healthy habit after every import:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(data)\nstr(data)\nsummary(data)\n```\n:::\n\n\n## Final Thoughts\n\nIf you can:\n\n-   read data correctly,\n\n-   write data consciously,\n\n-   choose file formats intentionally,\n\nyou have already crossed one of the most important thresholds in data analysis.\n\nFor a complementary discussion, you may also find this article useful:\\\n<https://medium.com/p/e730f4a84b3b>\n\n------------------------------------------------------------------------\n\n**Extended version on Medium:**\\\n[https://medium.com/\\@Fatih.Tuzen/understanding-data-import-and-export-in-r-working-with-csv-and-excel-files-6322e61049b2](https://medium.com/@Fatih.Tuzen/understanding-data-import-and-export-in-r-working-with-csv-and-excel-files-6322e61049b2)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}