View(num_list)
num_list <- list(a = 1:3, b = 4:6, c = 7:9)
custom_function <- function(x) sum(x) * 2
result_list <- lapply(num_list, custom_function)
print(result_list)
word_list <- list("apple", "banana", "orange", "grape")
vowel_list <- lapply(word_list, function(word) grep("[aeiou]", strsplit(word, "")[[1]], value = TRUE))
print(vowel_list)
library(purrr)
num_list <- list(a = 1:3, b = 4:6, c = 7:9)
mapped_results <- map(num_list, ~ .x^2)
print(mapped_results)
text_list <- list("hello", "world", "R", "programming")
string_lengths <- map(text_list, nchar)
print(string_lengths)
library(microbenchmark)
# 1000x1000 boyutunda bir matris oluşturalım
matris_data <- matrix(rnorm(1000000), nrow = 1000)
# Toplamı hesaplamak için apply() fonksiyonunu kullanalım
benchmark_results <- microbenchmark(
apply_sum = apply(matris_data, 2, sum),
sapply_sum = sapply(matris_data, sum),
lapply_sum = lapply(matris_data, sum),
map_sum = map_dbl(as.list(matris_data), sum),  # map fonksiyonu için listeye çevirmemiz gerekiyor
times = 100
)
print(benchmark_results)
View(matris_data)
# Create a 100 x 100 matrix
matrix_data <- matrix(rnorm(10000), nrow = 100)
# Use apply() function to compute the sum for each column
benchmark_results <- microbenchmark(
apply_sum = apply(matrix_data, 2, sum),
sapply_sum = sapply(matrix_data, sum),
lapply_sum = lapply(matrix_data, sum),
map_sum = map_dbl(as.list(matrix_data), sum),  # We need to convert the matrix to a list for the map function
times = 100
)
print(benchmark_results)
rm(list=ls())
library(microbenchmark)
library(tidyr)
sales_data <- data.frame(
product = c("A", "B", "C"),
Jan = c(500, 600, 300),
Feb = c(450, 700, 320),
Mar = c(520, 640, 310)
)
sales_long <- pivot_longer(sales_data, cols = Jan:Mar,
names_to = "month", values_to = "sales")
sales_long
sales_wide <- pivot_wider(sales_long, names_from = month, values_from = sales)
sales_wide
sales_long <- pivot_longer(sales_data, cols = Jan:Feb,
names_to = "month", values_to = "sales",
values_drop_na = TRUE)
sales_long
sales_data <- data.frame(
product = c("A", "A", "B", "B", "C", "C"),
region = c("North", "South", "North", "South", "North", "South"),
Jan = c(500, NA, 600, 580, 300, 350),
Feb = c(450, 490, NA, 700, 320, 400)
)
sales_data
sales_long <- pivot_longer(sales_data, cols = Jan:Feb,
names_to = "month", values_to = "sales",
values_drop_na = TRUE)
sales_long
# Gerekli paketleri yükle
library(tidyr)
library(ggplot2)
# Veri setini oluştur
sales_data <- data.frame(
product = c("A", "B", "C"),
Jan = c(500, 600, 300),
Feb = c(450, 700, 320),
Mar = c(520, 640, 310)
)
# Veriyi uzun formata dönüştür
sales_long <- pivot_longer(sales_data, cols = Jan:Mar,
names_to = "month", values_to = "sales")
# Çubuk grafiği oluştur
ggplot(sales_long, aes(x = month, y = sales, fill = product)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Sales Data: Long Format Example", x = "Month", y = "Sales") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
Sys.info()
Sys.getlocale()
Sys.getenv()
Sys.getlocale()
sessionInfo()
source("set_locale.R")
file.path("~", ".Rprofile")
help(Startup)
R.home(component = "home")
readRenviron("~/.Renviron")
date_example <- as.Date("2024-09-21")
date_example <- as.Date("2024-09-21")
date_example
datetime_example <- as.POSIXct("2024-09-21 14:45:00", tz = "UTC")
datetime_example
library(lubridate)
# Convert date strings to Date objects
date1 <- ymd("2024-09-21")
date1
date2 <- dmy("21-09-2024")
date2
# Convert to date-time
datetime1 <- ymd_hms("2024-09-21 14:45:00", tz = "UTC")
datetime1
datetime2 <- mdy_hms("09/21/2024 02:45:00 PM", tz = "America/New_York")
datetime2
#| message: false
library(lubridate)
# Convert date strings to Date objects
date1 <- ymd("2024-09-21")
date1
date2 <- dmy("21-09-2024")
date2
# Convert to date-time
datetime1 <- ymd_hms("2024-09-21 14:45:00", tz = "UTC")
datetime1
datetime2 <- mdy_hms("09/21/2024 02:45:00 PM", tz = "America/New_York")
datetime2
library(lubridate)
# Parsing a date-time object
datetime <- ymd_hms("2024-09-30 14:45:30")
# Extracting components
year(datetime)
month(datetime)
day(datetime)
hour(datetime)
minute(datetime)
second(datetime)
# Extracting weekday
wday(datetime)
wday(datetime, label = TRUE)
wday(datetime, label = TRUE, abbr = FALSE)
# Extracting month by name
month(datetime, label = TRUE, abbr = FALSE)
# Changing the month by name
month(datetime) <- 7
datetime
# Set a different time zone
datetime_tz <- with_tz(datetime, "America/New_York")
datetime_tz
# Extract hour in the new time zone
hour(datetime_tz)  # Output: 4 (converted from UTC to EDT)
# Creating a duration of 1 day
one_day <- ddays(1)
one_day
# Duration of 2 hours and 30 minutes
duration_time <- dhours(2) + dminutes(30)
duration_time
# Adding a duration to a date
start_date <- ymd("2024-09-21")
end_date <- start_date + ddays(7)
end_date
# Creating a period of 2 years, 3 months, and 10 days
my_period <- years(2) + months(3) + days(10)
my_period  # Output: "2y 3m 10d"
# Adding the period to a date
new_date <- start_date + my_period
new_date  # Output: "2026-12-01"
start_date
# Adding a duration to a date
start_date <- ymd("2024-09-30")
# Adding the period to a date
new_date <- start_date + my_period
new_date
# Creating an interval between two dates
start_date <- ymd("2024-01-01")
end_date <- ymd("2024-12-31")
time_interval <- interval(start_date, end_date)
time_interval
# Checking how many days are in the interval
as.duration(time_interval)
# Creating an interval and calculating the duration
interval_span <- interval(ymd("2024-09-01"), ymd("2024-12-01"))
interval_duration <- as.duration(interval_span)  # Duration in seconds
# Adjusting the interval by adding a period
extended_interval <- interval_span + months(1)
interval_span
interval_duration
extended_interval
# Adjusting the interval by adding a period
extended_interval <- interval_span + months(1)
# Create an interval between two dates
start_date <- ymd("2024-09-01")
end_date <- ymd("2024-12-01")
interval_span <- interval(start_date, end_date)
# Extend the end date by 1 month
new_end_date <- end_date + months(1)
# Create a new interval with the updated end date
extended_interval <- interval(start_date, new_end_date)
# Display the extended interval
extended_interval  # Output: "2024-09-01 UTC--2025-01-01 UTC"
# Example of irregular dates (missing some days)
irregular_dates <- c(ymd("2023-01-01"), ymd("2023-01-02"), ymd("2023-01-05"),
ymd("2023-01-07"), ymd("2023-01-10"))
# Create a dataset with missing dates
irregular_data <- data.frame(
date = irregular_dates,
value = runif(5, min = 100, max = 200)
)
# Complete the time series by filling missing dates
complete_dates <- data.frame(
date = seq(min(irregular_data$date), max(irregular_data$date), by = "day")
)
# Join the original data with the complete sequence of dates
complete_data <- merge(complete_dates, irregular_data, by = "date", all.x = TRUE)
# View the completed data with missing values
complete_data
# Converting a ts object to a data frame with dates
ts_data <- ts(sales_data, start = c(2020, 1), frequency = 12)
# Create a data frame from the ts object
df_ts <- data.frame(
date = seq(ymd("2020-01-01"), by = "month", length.out = length(ts_data)),
sales = as.numeric(ts_data)
)
# Extract year and month using lubridate
df_ts <- df_ts %>%
mutate(year = year(date), month = month(date))
library(dplyr)
#| message: false
library(dplyr)
# Sample dataset: daily values over one month
set.seed(123)
time_series_data <- data.frame(
date = seq(ymd("2023-01-01"), by = "day", length.out = 30),
value = runif(30, min = 50, max = 150)
)
# Aggregating the data by week
weekly_data <- time_series_data %>%
mutate(week = floor_date(date, "week")) %>%
group_by(week) %>%
summarize(weekly_avg = mean(value))
# View the aggregated data
weekly_data
# Converting a ts object to a data frame with dates
ts_data <- ts(sales_data, start = c(2020, 1), frequency = 12)
# Create a data frame from the ts object
df_ts <- data.frame(
date = seq(ymd("2020-01-01"), by = "month", length.out = length(ts_data)),
sales = as.numeric(ts_data)
)
# Extract year and month using lubridate
df_ts <- df_ts %>%
mutate(year = year(date), month = month(date))
# View the data with extracted components
df_ts
sales_data
View(sales_data)
# Sample data: monthly sales from 2020 to 2022
sales_data <- c(100, 120, 150, 170, 160, 130, 140, 180, 200, 190, 210, 220,
230, 250, 270, 300, 280, 260, 290, 310, 330, 340, 350, 360)
# Creating a time series object (monthly data starting from Jan 2020)
ts_sales <- ts(sales_data, start = c(2020, 1), frequency = 12)
ts_sales
# Convert time series to a data frame with date information
sales_df <- data.frame(
date = seq(ymd("2020-01-01"), by = "month", length.out = length(ts_sales)),
sales = as.numeric(ts_sales)
)
# Display the resulting data frame
sales_df
# Generate a sequence of daily dates
daily_dates <- seq(ymd("2023-01-01"), by = "day", length.out = 30)
# Create a sample dataset with random values for each day
daily_data <- data.frame(
date = daily_dates,
value = runif(30, min = 100, max = 200)
)
# View the first few rows of the dataset
head(daily_data)
#| message: false
library(dplyr)
# Sample dataset: daily values over one month
set.seed(123)
time_series_data <- data.frame(
date = seq(ymd("2023-01-01"), by = "day", length.out = 30),
value = runif(30, min = 50, max = 150)
)
# Aggregating the data by week
weekly_data <- time_series_data |>
mutate(week = floor_date(date, "week")) |>
group_by(week) |>
summarize(weekly_avg = mean(value))
# View the aggregated data
weekly_data
# Example of irregular dates (missing some days)
irregular_dates <- c(ymd("2023-01-01"), ymd("2023-01-02"), ymd("2023-01-05"),
ymd("2023-01-07"), ymd("2023-01-10"))
# Create a dataset with missing dates
irregular_data <- data.frame(
date = irregular_dates,
value = runif(5, min = 100, max = 200)
)
# Complete the time series by filling missing dates
complete_dates <- data.frame(
date = seq(min(irregular_data$date), max(irregular_data$date), by = "day")
)
# Join the original data with the complete sequence of dates
complete_data <- merge(complete_dates, irregular_data, by = "date", all.x = TRUE)
# View the completed data with missing values
complete_data
# Converting a ts object to a data frame with dates
ts_data <- ts(sales_data, start = c(2020, 1), frequency = 12)
# Create a data frame from the ts object
df_ts <- data.frame(
date = seq(ymd("2020-01-01"), by = "month", length.out = length(ts_data)),
sales = as.numeric(ts_data)
)
# Extract year and month using lubridate
df_ts <- df_ts %>%
mutate(year = year(date), month = month(date))
# View the data with extracted components
df_ts
#| eval: false
parse_date_time(x, orders, tz = "UTC", quiet = FALSE)
# Example date-time strings in various formats
dates <- c("2024-01-15", "01/16/2024", "March 17, 2024", "18-04-2024")
# Parse the dates using parse_date_time
parsed_dates <- parse_date_time(dates, orders = c("ymd", "mdy", "dmy", "B d, Y"))
# Display the parsed dates
parsed_dates
hours(3)
# Define task durations
task_duration <- hours(3)  # Each task takes 3 hours
start_time <- ymd_hms("2024-01-01 09:00:00")
# Schedule three tasks
schedule <- start_time + task_duration * 0:2
# Display the schedule for tasks
schedule
rm(list=ls())
# Load packages
library(openxlsx)
library(dplyr)
library(ggplot2)
#| message: false
# Load packages
library(openxlsx)
library(dplyr)
library(ggplot2)
# Create sample sales data
sales_data <- data.frame(
Date = seq(as.Date("2024-01-01"), by = "month", length.out = 12),
Product = rep(c("Product A", "Product B"), each = 6),
Sales = round(runif(12, 1000, 5000)),
Revenue = round(runif(12, 10000, 50000))
)
# Calculate monthly summaries
monthly_summary <- sales_data %>%
group_by(Product) %>%
summarise(
Total_Sales = sum(Sales),
Avg_Revenue = mean(Revenue),
Max_Revenue = max(Revenue)
)
monthly_summary
sales_data <- data.frame(
Date = seq.Date(as.Date("2023-01-01"), as.Date("2023-12-31"), by = "month"),
Region = rep(c("North", "South", "East", "West"), 3),
Sales = round(runif(12, 10000, 50000), 2),
Units = round(runif(12, 100, 500)),
Profit = round(runif(12, 5000, 25000), 2)
)
sales_data <- data.frame(
Date = seq.Date(as.Date("2023-01-01"), as.Date("2023-12-31"), by = "month"),
Region = rep(c("North", "South", "East", "West"), 3),
Sales = round(runif(12, 10000, 50000), 2),
Units = round(runif(12, 100, 500)),
Profit = round(runif(12, 5000, 25000), 2)
)
# Create regional summary
regional_summary <- sales_data %>%
group_by(Region) %>%
summarise(
Total_Sales = sum(Sales),
Avg_Units = mean(Units),
Total_Profit = sum(Profit)
)
regional_summary
sales_data
# Create new workbook
wb <- createWorkbook()
# Add worksheets
addWorksheet(wb, "Summary")
addWorksheet(wb, "Details")
addWorksheet(wb, "Charts")
# Create a title style
title_style <- createStyle(
fontSize = 14,
fontColour = "#FFFFFF",
halign = "center",
fgFill = "#4F81BD",
textDecoration = "bold",
border = "TopBottom",
borderColour = "#4F81BD"
)
# Create header style
header_style <- createStyle(
fontSize = 12,
fontColour = "#000000",
halign = "center",
fgFill = "#DCE6F1",
textDecoration = "bold",
border = "bottom",
borderColour = "#4F81BD"
)
# Write title
writeData(wb, "Summary", "Sales Performance Report 2023", startCol = 1, startRow = 1)
mergeCells(wb, "Summary", cols = 1:5, rows = 1)
addStyle(wb, "Summary", title_style, rows = 1, cols = 1:5)
# Write data with headers
writeData(wb, "Summary", sales_data, startCol = 1, startRow = 3)
addStyle(wb, "Summary", header_style, rows = 3, cols = 1:5)
# Format numbers
number_style <- createStyle(numFmt = "#,##0.00")
addStyle(wb, "Summary", number_style, rows = 4:15, cols = 3:5, gridExpand = TRUE)
# Adjust column widths
setColWidths(wb, "Summary", cols = 1:5, widths = "auto")
# Create monthly sales trend chart
sales_plot <- ggplot(sales_data, aes(x = Date, y = Sales)) +
geom_line(color = "#4F81BD", size = 1.2) +
geom_point(color = "#4F81BD", size = 3) +
theme_minimal() +
labs(title = "Monthly Sales Trend",
x = "Month",
y = "Sales ($)") +
theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
# Save plot to workbook
print(sales_plot)
insertPlot(wb, "Charts", width = 8, height = 6,
startCol = 1, startRow = 1)
# Create regional summary
regional_summary <- sales_data %>%
group_by(Region) %>%
summarise(
Total_Sales = sum(Sales),
Avg_Units = mean(Units),
Total_Profit = sum(Profit)
)
# Write regional summary to Details sheet
writeData(wb, "Details", "Regional Performance Summary", startCol = 1, startRow = 1)
mergeCells(wb, "Details", cols = 1:4, rows = 1)
addStyle(wb, "Details", title_style, rows = 1, cols = 1:4)
writeData(wb, "Details", regional_summary, startCol = 1, startRow = 3)
addStyle(wb, "Details", header_style, rows = 3, cols = 1:4)
# Save the workbook
saveWorkbook(wb, "Sales_Report_2023.xlsx", overwrite = TRUE)
library(OECD)
get_dataset()
datasets <- get_datasets()
install.packages("OECD")
install.packages("OECD")
library(OECD)
datasets <- get_datasets()
datasets <- get_datasets()
library(devtools)
install_github("expersso/OECD")
detach("package:OECD", unload = TRUE)
install_github("expersso/OECD")
library(OECD)
dataset <- "OECD.SDD.TPS/DSD_LFS@DF_IALFS_UNE_M,1.0"
filter <- "BEL+AUS+AUT+CAN+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ITA+JPN+LTU+LVA+LUX+NLD+NZL+POL+NOR+PRT+SVK+SVN+ESP+SWE+CHE+USA+GBR+TUR..PT_LF_SUB._Z.Y._T.Y_GE15..M"
df <- get_dataset(dataset, filter, start_time = 2014)
View(df)
url = "https://sdmx.oecd.org/public/rest/data/OECD.SDD.STES,DSD_STES@DF_CLI/.M.LI...AA...H?startPeriod=2023-02&dimensionAtObservation=AllDimensions&format=csvfilewithlabels"
df<-read.csv(url)
View(df)
url2 <- "https://sdmx.oecd.org/public/rest/dataflow/OECD.SDD.TPS/DSD_LFS@DF_IALFS_UNE_M/1.0?references=all"
df<-read.csv(url)
df<-read.csv(url2)
View(df)
url2 <- "https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0/BEL+AUS+AUT+CAN+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ITA+JPN+LTU+LVA+LUX+NLD+NZL+POL+NOR+PRT+SVK+SVN+ESP+SWE+CHE+USA+GBR+TUR..PT_LF_SUB._Z.Y._T.Y_GE15..M?startPeriod=2023-11&dimensionAtObservation=AllDimensions"
df<-read.csv(url2)
View(df)
url2 <- "https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0/BEL+AUS+AUT+CAN+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ITA+JPN+LTU+LVA+LUX+NLD+NZL+POL+NOR+PRT+SVK+SVN+ESP+SWE+CHE+USA+GBR+TUR..PT_LF_SUB._Z.Y._T.Y_GE15..M?startPeriod=2023-11&dimensionAtObservation=AllDimensions&format=csvfilewithlabels"
df<-read.csv(url2)
data <- get_dataset("DP_LIVE",
filter = list(LOCATION = "USA",
SUBJECT = "TOT",
MEASURE = "PC_CHG",
TIME = "2020-2023"))
library(OECD)
xx <- get_data_structure("OECD.SDD.NAD.SEEA/DSD_NAT_RES@DF_NAT_RES/1.0")
View(xx)
xx <- get_data_structure("OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0")
View(xx)
xx
summary(xx)
dataset <- "OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0"
get_data_structure(dataset)
data_str <- get_data_structure(dataset)
summary(data_str)
data_filters <- "BEL+AUS+AUT+CAN+DNK+FRA+DEU+GRC+HUN+IRL+ITA+JPN+NLD+NZL+NOR+PRT+SVN+ESP+SWE+CHE+USA+GBR+TUR..PT_LF_SUB._Z.Y._T.Y_GE15..M"
dataset_unemprate <- "OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0"
data_str <- get_data_structure(dataset_unemprate)
str(data_str, max.level = 1)
library(OECD)
# Load the rsdmx package
library(rsdmx)
# Define the API URL for unemployment rates
oecd_url <- "https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_LFS@DF_IALFS_UNE_M,1.0/BEL+AUS+AUT+CAN+DNK+FRA+DEU+GRC+HUN+IRL+ITA+JPN+NLD+NZL+NOR+PRT+SVN+ESP+SWE+CHE+USA+GBR+TUR..PT_LF_SUB._Z.Y._T.Y_GE15..M?startPeriod=2023-11&dimensionAtObservation=AllDimensions"
# Step 1: Fetch the data
unemployment_data <- readSDMX(oecd_url)
# Step 2: Convert to a data frame
unemployment_df <- as.data.frame(unemployment_data)
# View the data
head(unemployment_df)
